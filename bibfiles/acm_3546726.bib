@article{10.1145/3546726,
author = {Stampf, Annika and Colley, Mark and Rukzio, Enrico},
title = {Towards Implicit Interaction in Highly Automated Vehicles - A Systematic Literature Review},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {MHCI},
url = {https://doi.org/10.1145/3546726},
doi = {10.1145/3546726},
abstract = {The inclusion of in-vehicle sensors and increased intention and state recognition capabilities enable implicit in-vehicle interaction. Starting from a systematic literature review (SLR) on implicit in-vehicle interaction, which resulted in 82 publications, we investigated state and intention recognition methods based on (1) their used modalities, (2) their underlying level of automation, and (3) their considered interaction focus. Our SLR revealed a research gap addressing implicit interaction in highly automated vehicles (HAVs). Therefore, we discussed how the requirements for implicit state and intention recognition methods and interaction based on them are changing in HAVs. With this, open questions and opportunities for further research in this area were identified.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {sep},
articleno = {191},
numpages = {21},
keywords = {implicit interaction, systematic literature review, in-vehicle interaction}
}

@article{10.1145/3442694,
author = {Bluemke, Ilona and Malanowska, Agnieszka},
title = {Software Testing Effort Estimation and Related Problems: A Systematic Literature Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442694},
doi = {10.1145/3442694},
abstract = {Although testing effort estimation is a very important task in software project management, it is rarely described in the literature. There are many difficulties in finding any useful methods or tools for this purpose. Solutions to many other problems related to testing effort calculation are published much more often. There is also no research focusing on both testing effort estimation and all related areas of software engineering. To fill this gap, we performed a systematic literature review on both questions. Although our primary objective was to find some tools or implementable metods for test effort estimation, we have quickly discovered many other interesting topics related to the main one. The main contribution of this work is the presentation of the testing effort estimation task in a very wide context, indicating the relations with other research fields. This systematic literature review presents a detailed overview of testing effort estimation task, including challenges and approaches to automating it and the solutions proposed in the literature. It also exhaustively investigates related research topics, classifying publications that can be found in connection to the testing effort according to seven criteria formulated on the basis of our research questions. We present here both synthesis of our finding and the deep analysis of the stated research problems.},
journal = {ACM Comput. Surv.},
month = {apr},
articleno = {53},
numpages = {38},
keywords = {testing effort estimation, testing effort estimation-related problems, Testing effort, systematic literature review}
}

@inproceedings{10.1145/3530019.3530028,
author = {van Heugten Breurkes, Jack and Gilson, Fabian and Galster, Matthias},
title = {Overlap between Automated Unit and Acceptance Testing – a Systematic Literature Review},
year = {2022},
isbn = {9781450396134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530019.3530028},
doi = {10.1145/3530019.3530028},
abstract = {Unit and automated acceptance testing have different objectives (e.g., testing units of code versus testing complete features). Testing practices (e.g., test-first, model-based) used for one “level” of testing (for either unit or acceptance testing) may require knowledge and skills that are not applicable to the other. This makes it difficult for practitioners to gain the skills required to effectively test at all levels and form a cohesive testing strategy. The aim of this systematic literature review is to understand whether there are any automated unit testing practices that have similarities with automated acceptance testing practices (and vice versa). Understanding these similarities can enable skill transfer across testing activities at different levels. This systematic literature review focuses on empirical research with an industry focus. We found that test-driven development (TDD) and model-based test generation (MBTG) are two practices widely researched for both unit testing and acceptance testing. For TDD we found that a design- and test-first mindset is required and helpful at both the unit and acceptance levels, but practitioners struggle with that practice. For MBTG we found that, despite its ability to increase code coverage, the additional manual effort to enable automated test generation may outweigh its benefits.},
booktitle = {Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering},
pages = {80–89},
numpages = {10},
keywords = {automated testing, testing strategy, model-based test generation, acceptance testing, unit testing, test-driven development},
location = {Gothenburg, Sweden},
series = {EASE '22}
}

@article{10.1145/3462477,
author = {Ignaczak, Luciano and Goldschmidt, Guilherme and Costa, Cristiano Andr\'{e} Da and Righi, Rodrigo Da Rosa},
title = {Text Mining in Cybersecurity: A Systematic Literature Review},
year = {2021},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3462477},
doi = {10.1145/3462477},
abstract = {The growth of data volume has changed cybersecurity activities, demanding a higher level of automation. In this new cybersecurity landscape, text mining emerged as an alternative to improve the efficiency of the activities involving unstructured data. This article proposes a Systematic Literature Review (SLR) to present the application of text mining in the cybersecurity domain. Using a systematic protocol, we identified 2,196 studies, out of which 83 were summarized. As a contribution, we propose a taxonomy to demonstrate the different activities in the cybersecurity domain supported by text mining. We also detail the strategies evaluated in the application of text mining tasks and the use of neural networks to support activities involving unstructured data. The work also discusses text classification performance aiming its application in real-world solutions. The SLR also highlights open gaps for future research, such as the analysis of non-English content and the intensification in the usage of neural networks.},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {140},
numpages = {36},
keywords = {natural language processing, text mining, Cybersecurity, systematic literature review}
}

@inproceedings{10.1145/3593434.3594239,
author = {Ramzan, Sidra and Khan, Saif-UR-Rehman and Hussain, Shahid and Wang, Wen-Li and Tang, Mei-Huei},
title = {Identification of Influential Factors for Successful Adoption of DevOps and Cloud},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3594239},
doi = {10.1145/3593434.3594239},
abstract = {DevOps is a software development approach that emphasize collaboration, communication and integration between development and operation teams to improve the speed and efficiency of software delivery. DevOps aims to automate and streamline the software development and deployment process. Nevertheless, when a software organization adopts DevOps, several challenges on infrastructure management, limited agility, scalability, increased cost, inconsistent environment, and security risks are faced. A solution is to adopt DevOps and Cloud together, but the integration requires advice because implementing new approaches for development and operations at the same time is also a challenge. The aim of this study is to identify and categorize success factors that positively influence the adoption of DevOps and Cloud in software organization and propose an integrated framework for factors of both dimensions. A systematic literature review (SLR) was conducted to collect the primary studies related to both fields for analysis. After the SLR, 40 success factors related to DevOps and Cloud are collected. These identified factors are further categorized into Technical, Organizational, and Social &amp; Culture areas. The proposed framework can help practitioners and researchers to concentrate on the crucial areas that are essential for the successful adoption of DevOps and Cloud.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {423–429},
numpages = {7},
keywords = {Success factors, DevOps, Cloud Computing, Systematic Literature Review},
location = {Oulu, Finland},
series = {EASE '23}
}

@article{10.1145/3469440,
author = {Gheibi, Omid and Weyns, Danny and Quin, Federico},
title = {Applying Machine Learning in Self-Adaptive Systems: A Systematic Literature Review},
year = {2021},
issue_date = {September 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1556-4665},
url = {https://doi.org/10.1145/3469440},
doi = {10.1145/3469440},
abstract = {Recently, we have been witnessing a rapid increase in the use of machine learning techniques in self-adaptive systems. Machine learning has been used for a variety of reasons, ranging from learning a model of the environment of a system during operation to filtering large sets of possible configurations before analyzing them. While a body of work on the use of machine learning in self-adaptive systems exists, there is currently no systematic overview of this area. Such an overview is important for researchers to understand the state of the art and direct future research efforts. This article reports the results of a systematic literature review that aims at providing such an overview. We focus on self-adaptive systems that are based on a traditional Monitor-Analyze-Plan-Execute (MAPE)-based feedback loop. The research questions are centered on the problems that motivate the use of machine learning in self-adaptive systems, the key engineering aspects of learning in self-adaptation, and open challenges in this area. The search resulted in 6,709 papers, of which 109 were retained for data collection. Analysis of the collected data shows that machine learning is mostly used for updating adaptation rules and policies to improve system qualities, and managing resources to better balance qualities and resources. These problems are primarily solved using supervised and interactive learning with classification, regression, and reinforcement learning as the dominant methods. Surprisingly, unsupervised learning that naturally fits automation is only applied in a small number of studies. Key open challenges in this area include the performance of learning, managing the effects of learning, and dealing with more complex types of goals. From the insights derived from this systematic literature review, we outline an initial design process for applying machine learning in self-adaptive systems that are based on MAPE feedback loops.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {aug},
articleno = {9},
numpages = {37},
keywords = {MAPE-K, Self-adaptation, feedback loops}
}

@inproceedings{10.1145/3475716.3484189,
author = {Sultana, Sayma and Sarker, Jaydeb and Bosu, Amiangshu},
title = {A Rubric to Identify Misogynistic and Sexist Texts from Software Developer Communications},
year = {2021},
isbn = {9781450386654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3475716.3484189},
doi = {10.1145/3475716.3484189},
abstract = {Background: As contemporary software development organizations are dominated by males, occurrences of misogynistic and sexist remarks are abundant in many communities. Such remarks are barriers to promoting diversity and inclusion in the software engineering (SE) domain.Aims: This study aims to develop a rubric to identify misogynistic remarks and sexist jokes specifically from software developer communications.Method: We have followed the systematic literature review protocol to identify 10 primary studies that have characterized misogynistic and sexist texts in various domains.Results: Based on our syntheses of the primary studies, we have developed a rubric to manually identity various categories of misogynistic or sexist remarks. We have also provided SE domain specific examples of those categories.Conclusions: Our annotation guideline will pave the path towards building automated misogynistic text classifier for the SE domain.},
booktitle = {Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)},
articleno = {27},
numpages = {6},
keywords = {software developer, sexist joke, misogynistic text},
location = {Bari, Italy},
series = {ESEM '21}
}

@inproceedings{10.1145/3535511.3535531,
author = {Campos, Thiago Prado de and Damasceno, Eduardo Filgueiras and Valentim, Natasha Malveira Costa},
title = {Proposal and Evaluation of a Collaborative IS to Support Systematic Reviews and Mapping Studies},
year = {2022},
isbn = {9781450396981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3535511.3535531},
doi = {10.1145/3535511.3535531},
abstract = {Context: Systematic Literature Review (SLR) or Systematic Mapping Study (SMS) are a process in which publications dataset is systematically analyzed to cover a research field. These processes involve multiple investigators collaborating to produce more improved work and often use automated tools to facilitate their work. Problem: However, not all tools offer proper support to collaborative SLR or SMS. That is, missing a tool to support the study selection process, allowing the collaboration between researchers by applying individual criteria and collective decision, supported by agreement or discussion and consensus. Solution: We developed the Porifera tool to fill this lack. IS Theory: Technology Acceptance Model (TAM) and a Grounded Theory’s phase subset were used to evaluate Porifera’s tool quality. Methodology: Undergraduate and postgraduate students enrolled in the Experimental Software Engineering Research,used the Porifera tool and answered a post-used questionnaire with TAM’s sentences and other open questions. Then, a quantitative and qualitative analysis was performed. Summary of Results: It was possible to see high perceived usefulness and ease of use for Porifera. Too it noted the effectiveness of resources to support the collaborative activity and its contribution to learning and performing a collaborative SLR or SMS. The evaluation showed points to improve the Porifera’s interface. Contribution and Impact in the IS area: The Porifera is an IS for data, information, and knowledge research management because it gathers publications records and allows it will be interpreted and processed, making possible decisions making by researchers. The Porifera also allows performing an SLR or SMS with mobility, knowledge sharing, flexibility, and integration between people and technology.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Information Systems},
articleno = {20},
numpages = {8},
keywords = {user feedback, SLR tool, collaborative system, Systematic Literature Review, Systematic Mapping Study, software evaluation},
location = {Curitiba, Brazil},
series = {SBSI '22}
}

@article{10.1145/3556974,
author = {Senanayake, Janaka and Kalutarage, Harsha and Al-Kadri, Mhd Omar and Petrovski, Andrei and Piras, Luca},
title = {Android Source Code Vulnerability Detection: A Systematic Literature Review},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3556974},
doi = {10.1145/3556974},
abstract = {The use of mobile devices is rising daily in this technological era. A continuous and increasing number of mobile applications are constantly offered on mobile marketplaces to fulfil the needs of smartphone users. Many Android applications do not address the security aspects appropriately. This is often due to a lack of automated mechanisms to identify, test, and fix source code vulnerabilities at the early stages of design and development. Therefore, the need to fix such issues at the initial stages rather than providing updates and patches to the published applications is widely recognized. Researchers have proposed several methods to improve the security of applications by detecting source code vulnerabilities and malicious codes. This Systematic Literature Review (SLR) focuses on Android application analysis and source code vulnerability detection methods and tools by critically evaluating 118 carefully selected technical studies published between 2016 and 2022. It highlights the advantages, disadvantages, applicability of the proposed techniques, and potential improvements of those studies. Both Machine Learning (ML)-based methods and conventional methods related to vulnerability detection are discussed while focusing more on ML-based methods, since many recent studies conducted experiments with ML. Therefore, this article aims to enable researchers to acquire in-depth knowledge in secure mobile application development while minimizing the vulnerabilities by applying ML methods. Furthermore, researchers can use the discussions and findings of this SLR to identify potential future research and development directions.},
journal = {ACM Comput. Surv.},
month = {jan},
articleno = {187},
numpages = {37},
keywords = {vulnerability detection, Android security, software security, machine learning, Source code vulnerability}
}

@inproceedings{10.1145/3528588.3528658,
author = {Alchokr, Rand and Borkar, Manoj and Thotadarya, Sharanya and Saake, Gunter and Leich, Thomas},
title = {Supporting Systematic Literature Reviews Using Deep-Learning-Based Language Models},
year = {2023},
isbn = {9781450393430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528588.3528658},
doi = {10.1145/3528588.3528658},
abstract = {Background: Systematic Literature Reviews are an important research method for gathering and evaluating the available evidence regarding a specific research topic. However, the process of conducting a Systematic Literature Review manually can be difficult and time-consuming. For this reason, researchers aim to semi-automate this process or some of its phases. Aim: We aimed at using a deep-learning based contextualized embeddings clustering technique involving transformer-based language models and a weighted scheme to accelerate the conduction phase of Systematic Literature Reviews for efficiently scanning the initial set of retrieved publications. Method: We performed an experiment using two manually conducted SLRs to evaluate the performance of two deep-learning-based clustering models. These models build on transformer-based deep language models (i.e., BERT and S-BERT) to extract contextualized embeddings on different text levels along with a weighted scheme to cluster similar publications. Results: Our primary results show that clustering based on embedding at paragraph-level using S-BERT-paragraph represents the best performing model setting in terms of optimizing the required parameters such as correctly identifying primary studies, number of additional documents identified as part of the relevant cluster and the execution time of the experiments. Conclusions: The findings indicate that using natural-language-based deep-learning architectures for semi-automating the selection of primary studies can accelerate the scanning and identification process. While our results represent first insights only, such a technique seems to enhance SLR process, promising to help researchers identify the most relevant publications more quickly and efficiently.},
booktitle = {Proceedings of the 1st International Workshop on Natural Language-Based Software Engineering},
pages = {67–74},
numpages = {8},
keywords = {systematic literature review, language models, deep learning, BERT},
location = {Pittsburgh, Pennsylvania},
series = {NLBSE '22}
}

@inproceedings{10.1145/3512676.3512705,
author = {Sasi, Archana and Subramanian, Thiruselvan and Kumar Ravichandran, Sathish},
title = {Systematic Literature Review on Industry Revolution 4.0 to Enhance Supply Chain Operation Performance},
year = {2022},
isbn = {9781450387422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512676.3512705},
doi = {10.1145/3512676.3512705},
abstract = {Industry 4.0 is a notion in which industries automate systems and processes, innovate digitally, and share information. It aims to obtain a smart factory in an attempt to lessen required time in responding to consumer demand or unexpected circumstances and to enhance organizational productivity. The integration of Industry 4.0 and supply chain management (SCM) ensures immense development opportunities for manufacturing firms. This article provides a systematic literature review and formulation of the existing research on Industry 4.0 in SCM, resulting in some intriguing analyses that will be useful to academics and industry, particularly top managers. The content of the article is classified into three categories: exploratory vs. confirmatory, qualitative vs. quantitative, and management level vs. technology level. The findings will benefit managers in understanding the significance of Industry 4.0 and its relationship with SCM. The formation of clusters and their affiliations has resulted in the emergence of new areas requiring managerial attention. The article concludes by examining the possibilities of the present and future research.},
booktitle = {Proceedings of the 2022 5th International Conference on Computers in Management and Business},
pages = {173–179},
numpages = {7},
keywords = {Digital Technologies, Industry 4.0, SCM 4.0, Global Supply Chain, Supply Chain Management},
location = {Singapore, Singapore},
series = {ICCMB '22}
}

@article{10.1145/3534617,
author = {Jansen, Pascal and Colley, Mark and Rukzio, Enrico},
title = {A Design Space for Human Sensor and Actuator Focused In-Vehicle Interaction Based on a Systematic Literature Review},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3534617},
doi = {10.1145/3534617},
abstract = {Automotive user interfaces constantly change due to increasing automation, novel features, additional applications, and user demands. While in-vehicle interaction can utilize numerous promising modalities, no existing overview includes an extensive set of human sensors and actuators and interaction locations throughout the vehicle interior. We conducted a systematic literature review of 327 publications leading to a design space for in-vehicle interaction that outlines existing and lack of work regarding input and output modalities, locations, and multimodal interaction. To investigate user acceptance of possible modalities and locations inferred from existing work and gaps unveiled in our design space, we conducted an online study (N=48). The study revealed users' general acceptance of novel modalities (e.g., brain or thermal activity) and interaction with locations other than the front (e.g., seat or table). Our work helps practitioners evaluate key design decisions, exploit trends, and explore new areas in the domain of in-vehicle interaction.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {jul},
articleno = {56},
numpages = {51},
keywords = {in-vehicle interaction, human sensors and actuators, systematic literature review, design space}
}

@inproceedings{10.1145/3387940.3392233,
author = {S\'{a}nchez-Gord\'{o}n, Mary and Colomo-Palacios, Ricardo},
title = {Security as Culture: A Systematic Literature Review of DevSecOps},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392233},
doi = {10.1145/3387940.3392233},
abstract = {DevOps goes beyond automation, continuous integration and delivery processes, since it also encompasses people. In fact, DevOps promotes the collaboration between the development team and the operations team. When security comes into DevOps routines, people play an even more relevant role involving the collaboration between those teams and security team. Moreover, security is especially relevant while developing critical systems where we need to manage goals, risks and evidences. After implementing security into the DevOps toolchain, work only starts. We also need to start with behavioral changes in order to create a security culture. Several authors underlined DevSecOps, as one of the proposals for solving or, at least, minimizing this challenge. However, to date, the characterization of such a culture remains unclear. In this paper, a Systematic Literature Review was carried out to provide a better understanding of this topic from the human factor's perspective. However it raises the following question: Is DevSecOps going to become mainstream?},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {266–269},
numpages = {4},
keywords = {Culture, Human factors, Systematic Literature Review, DevSecOps, Security},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1145/3442181,
author = {Sabir, Bushra and Ullah, Faheem and Babar, M. Ali and Gaire, Raj},
title = {Machine Learning for Detecting Data Exfiltration: A Review},
year = {2021},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3442181},
doi = {10.1145/3442181},
abstract = {Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {50},
numpages = {47},
keywords = {data breach, advanced persistent threat, Data exfiltration, data leakage, machine learning}
}

@inproceedings{10.1145/3581641.3584078,
author = {Ko, Hyung-Kwon and Park, Gwanmo and Jeon, Hyeon and Jo, Jaemin and Kim, Juho and Seo, Jinwook},
title = {Large-Scale Text-to-Image Generation Models for Visual Artists’ Creative Works},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584078},
doi = {10.1145/3581641.3584078},
abstract = {Large-scale Text-to-image Generation Models (LTGMs) (e.g., DALL-E), self-supervised deep learning models trained on a huge dataset, have demonstrated the capacity for generating high-quality open-domain images from multi-modal input. Although they can even produce anthropomorphized versions of objects and animals, combine irrelevant concepts in reasonable ways, and give variation to any user-provided images, we witnessed such rapid technological advancement left many visual artists disoriented in leveraging LTGMs more actively in their creative works. Our goal in this work is to understand how visual artists would adopt LTGMs to support their creative works. To this end, we conducted an interview study as well as a systematic literature review of 72 system/application papers for a thorough examination. A total of 28 visual artists covering 35 distinct visual art domains acknowledged LTGMs’ versatile roles with high usability to support creative works in automating the creation process (i.e., automation), expanding their ideas (i.e., exploration), and facilitating or arbitrating in communication (i.e., mediation). We conclude by providing four design guidelines that future researchers can refer to in making intelligent user interfaces using LTGMs.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {919–933},
numpages = {15},
keywords = {DALL-E, literature review, Large-scale text-to-image generation model, visual artists, interview study},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

@inproceedings{10.1145/3472675.3473974,
author = {Fontes, Afonso and Gay, Gregory},
title = {Using Machine Learning to Generate Test Oracles: A Systematic Literature Review},
year = {2021},
isbn = {9781450386265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3472675.3473974},
doi = {10.1145/3472675.3473974},
abstract = {Machine learning may enable the automated generation of test oracles. We have characterized emerging research in this area through a systematic literature review examining oracle types, researcher goals, the ML techniques applied, how the generation process was assessed, and the open research challenges in this emerging field.  Based on a sample of 22 relevant studies, we observed that ML algorithms generated test verdict, metamorphic relation, and---most commonly---expected output oracles. Almost all studies employ a supervised or semi-supervised approach, trained on labeled system executions or code metadata---including neural networks, support vector machines, adaptive boosting, and decision trees. Oracles are evaluated using the mutation score, correct classifications, accuracy, and ROC. Work-to-date show great promise, but there are significant open challenges regarding the requirements imposed on training data, the complexity of modeled functions, the ML algorithms employed---and how they are applied---the benchmarks used by researchers, and replicability of the studies. We hope that our findings will serve as a roadmap and inspiration for researchers in this field.},
booktitle = {Proceedings of the 1st International Workshop on Test Oracles},
pages = {1–10},
numpages = {10},
keywords = {Test Oracle, Automated Test Oracle Generation, Automated Test Generation, Machine Learning},
location = {Athens, Greece},
series = {TORACLE 2021}
}

@inproceedings{10.1145/3526073.3527584,
author = {Kolltveit, Ask Berstad and Li, Jingyue},
title = {Operationalizing Machine Learning Models: A Systematic Literature Review},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527584},
doi = {10.1145/3526073.3527584},
abstract = {Deploying machine learning (ML) models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non-trivial task, requiring extra care and infrastructure to deal with the additional challenges. Although many studies focus on adapting ML software engineering (SE) approaches and techniques, few studies have summarized the status and challenges of operationalizing ML models. Model operationalization encompasses all steps after model training and evaluation, including packaging the model in a format appropriate for deployment, publishing to a model registry or storage, integrating the model into a broader software system, serving, and monitoring. This study is the first systematic literature review investigating the techniques, tools, and infrastructures to operationalize ML models. After reviewing 24 primary studies, the results show that there are a number of tools for most use cases to operationalize ML models and cloud deployment in particular. The review also revealed several research opportunities, such as dynamic model-switching, continuous model-monitoring, and efficient edge ML deployments.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {1–8},
numpages = {8},
keywords = {MLOps, operationalization, systematic literature review, deployment, machine learning},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/3387904.3389251,
author = {Aung, Thazin Win Win and Huo, Huan and Sui, Yulei},
title = {A Literature Review of Automatic Traceability Links Recovery for Software Change Impact Analysis},
year = {2020},
isbn = {9781450379588},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387904.3389251},
doi = {10.1145/3387904.3389251},
abstract = {In large-scale software development projects, change impact analysis (CIA) plays an important role in controlling software design evolution. Identifying and accessing the effects of software changes using traceability links between various software artifacts is a common practice during the software development cycle. Recently, research in automated traceability-link recovery has received broad attention in the software maintenance community to reduce the manual maintenance cost of trace links by developers. In this study, we conducted a systematic literature review related to automatic traceability link recovery approaches with a focus on CIA. We identified 33 relevant studies and investigated the following aspects of CIA: traceability approaches, CIA sets, degrees of evaluation, trace direction and methods for recovering traceability link between artifacts of different types. Our review indicated that few traceability studies focused on designing and testing impact analysis sets, presumably due to the scarcity of datasets. Based on the findings, we urge further industrial case studies. Finally, we suggest developing traceability tools to support fully automatic traceability approaches, such as machine learning and deep learning.},
booktitle = {Proceedings of the 28th International Conference on Program Comprehension},
pages = {14–24},
numpages = {11},
keywords = {change impact analysis, traceability, natural language processing},
location = {Seoul, Republic of Korea},
series = {ICPC '20}
}

@inproceedings{10.1145/3422392.3422411,
author = {Camara, Rafael and Alves, Annelyelthon and Monte, Iury and Marinho, Marcelo},
title = {Agile Global Software Development: A Systematic Literature Review},
year = {2020},
isbn = {9781450387538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3422392.3422411},
doi = {10.1145/3422392.3422411},
abstract = {Global Software Development (GSD) continues to grow substantially and it is fast becoming the norm and fundamentally different from local Software Engineering development. Withal, agile software development (ASD) has become an appealing choice for companies attempting to improve their performance although its methods were originally designed for small and individual teams. The current literature does not provide a cohesive picture of how the agile practices are taken into account in the distributed nature of software development: how to do it, who, and what works in practice. This study aims to highlight how ASD practices are applied in the context of GSD in order to develop a set of techniques that can be relevant in both research and practice. To answer the research question, "how are agile practices adopted in agile global software development teams?" We conducted a systematic literature review of the ASD and GSD literature. A synthesis of solutions found in seventy-six studies provided 48 distinct practices that organizations can implement, including "collaboration among teams", "agile architecture", "coaching", "system demo" and "test automation". These implementable practices go some way towards providing solutions to manage GSD teams, and thus to embrace agility.},
booktitle = {Proceedings of the XXXIV Brazilian Symposium on Software Engineering},
pages = {31–40},
numpages = {10},
keywords = {Systematic Literature Review, Software engineering, Agile Software Development, Global Software Development},
location = {Natal, Brazil},
series = {SBES '20}
}

@inproceedings{10.1145/3393822.3432330,
author = {Daoudagh, Said and Lonetti, Francesca and Marchetti, Eda},
title = {Continuous Development and Testing of Access and Usage Control: A Systematic Literature Review},
year = {2020},
isbn = {9781450377621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393822.3432330},
doi = {10.1145/3393822.3432330},
abstract = {Context: Development and testing of access/usage control systems is a growing research area. With new trends in software development such as DevOps, the development of access/usage control also has to evolve. Objective: The main aim of this paper is to provide an overview of research proposals in the area of continuous development and testing of access and usage control systems. Method: The paper uses a Systematic Literature Review as a research method to define the research questions and answer them following a systematic approach. With the specified search string, 210 studies were retrieved. After applying the inclusion and exclusion criteria in two phases, a final set of 20 primary studies was selected for this review. Results: Results show that primary studies are mostly published in security venues followed by software engineering venues. Furthermore, most of the studies are based on the standard XACML access control language. In addition, a significant portion of the proposals for development and testing is automated with test assessment and generation the most targeted areas. Some general guidelines for leveraging continuous developing and testing of the usage and access control systems inside the DevOps process are also provided.},
booktitle = {Proceedings of the 2020 European Symposium on Software Engineering},
pages = {51–59},
numpages = {9},
keywords = {DevOps, XACML, Access Control, Testing, Systematic Literature Review},
location = {Rome, Italy},
series = {ESSE '20}
}

@article{10.1145/3485275,
author = {Watson, Cody and Cooper, Nathan and Palacio, David Nader and Moran, Kevin and Poshyvanyk, Denys},
title = {A Systematic Literature Review on the Use of Deep Learning in Software Engineering Research},
year = {2022},
issue_date = {April 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3485275},
doi = {10.1145/3485275},
abstract = {An increasingly popular set of techniques adopted by software engineering (SE) researchers to automate development tasks are those rooted in the concept of Deep Learning (DL). The popularity of such techniques largely stems from their automated feature engineering capabilities, which aid in modeling software artifacts. However, due to the rapid pace at which DL techniques have been adopted, it is difficult to distill the current successes, failures, and opportunities of the current research landscape. In an effort to bring clarity to this cross-cutting area of work, from its modern inception to the present, this article presents a systematic literature review of research at the intersection of SE &amp; DL. The review canvasses work appearing in the most prominent SE and DL conferences and journals and spans 128 papers across 23&nbsp;unique SE tasks. We center our analysis around the components of learning, a set of principles that governs the application of machine learning techniques (ML) to a given problem domain, discussing several aspects of the surveyed work at a granular level. The end result of our analysis is a research roadmap that both delineates the foundations of DL techniques applied to SE research and highlights likely areas of fertile exploration for the future.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {mar},
articleno = {32},
numpages = {58},
keywords = {neural networks, software engineering, machine learning, Deep learning, literature review}
}

@article{10.1145/3476066,
author = {Kim, Seunghyun and Razi, Afsaneh and Stringhini, Gianluca and Wisniewski, Pamela J. and De Choudhury, Munmun},
title = {A Human-Centered Systematic Literature Review of Cyberbullying Detection Algorithms},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3476066},
doi = {10.1145/3476066},
abstract = {Cyberbullying is a growing problem across social media platforms, inflicting short and long-lasting effects on victims. To mitigate this problem, research has looked into building automated systems, powered by machine learning, to detect cyberbullying incidents, or the involved actors like victims and perpetrators. In the past, systematic reviews have examined the approaches within this growing body of work, but with a focus on the computational aspects of the technical innovation, feature engineering, or performance optimization, without centering around the roles, beliefs, desires, or expectations of humans. In this paper, we present a human-centered systematic literature review of the past 10 years of research on automated cyberbullying detection. We analyzed 56 papers based on a three-prong human-centeredness algorithm design framework - spanning theoretical, participatory, and speculative design. We found that the past literature fell short of incorporating human-centeredness across multiple aspects, ranging from defining cyberbullying, establishing the ground truth in data annotation, evaluating the performance of the detection models, to speculating the usage and users of the models, including potential harms and negative consequences. Given the sensitivities of the cyberbullying experience and the deep ramifications cyberbullying incidents bear on the involved actors, we discuss takeaways on how incorporating human-centeredness in future research can aid with developing detection systems that are more practical, useful, and tuned to the diverse needs and contexts of the stakeholders.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {325},
numpages = {34},
keywords = {literature review, human-centered machine learning, social media, cyberbullying detection}
}

@inproceedings{10.1145/3587102.3588822,
author = {Messer, Marcus and Brown, Neil C. C. and K\"{o}lling, Michael and Shi, Miaojing},
title = {Machine Learning-Based Automated Grading and Feedback Tools for Programming: A Meta-Analysis},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588822},
doi = {10.1145/3587102.3588822},
abstract = {Research into automated grading has increased as Computer Science courses grow. Dynamic and static approaches are typically used to implement these graders, the most common implementation being unit testing to grade correctness. This paper expands upon an ongoing systematic literature review to provide an in-depth analysis of how machine learning (ML) has been used to grade and give feedback on programming assignments. We conducted a backward snowball search using the ML papers from an ongoing systematic review and selected 27 papers that met our inclusion criteria. After selecting our papers, we analysed the skills graded, the preprocessing steps, the ML implementation, and the models' evaluations.We find that most the models are implemented using neural network-based approaches, with most implementing some form of recurrent neural network (RNN), including Long Short-Term Memory, and encoder/decoder with attention mechanisms. Some graders implement traditional ML approaches, typically focused on clustering. Most ML-based automated grading, not many use ML to evaluate maintainability, readability, and documentation, but focus on grading correctness, a problem that dynamic and static analysis techniques, such as unit testing, rule-based program repair, and comparison to models or approved solutions, have mostly resolved. However, some ML-based tools, including those for assessing graphical output, have evaluated the correctness of assignments that conventional implementations cannot.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {491–497},
numpages = {7},
keywords = {automated grading, machine learning, meta-analysis, computer science education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.5555/3631672.3631693,
author = {Moreira, Rodrigo and Fernandes, Eduardo and Figueiredo, Eduardo},
title = {Review-Based Comparison of Design Pattern Detection Tools},
year = {2023},
isbn = {9781941652183},
publisher = {The Hillside Group},
address = {USA},
abstract = {Context: Design patterns are reusable solutions for recurring problems of software design. Although useful for software analysis, detecting design patterns is often challenging especially in large and complex software systems. In this context, several tools have been proposed for automating this process. Objective: Past attempts to summarize existing detection tools contain gaps in their scope, such as the lack of a comparison of the output provided by the tools in terms of precision and agreement. We address some of these gaps through a literature review and a comparison of design pattern detection tools. Our goal is to assist practitioners and researchers not only looking for useful tools, but also exploring opportunities for their improvements. Method: We present a systematic literature review of design pattern detection tools based on strict guidelines. We compare the performance of four tools in detecting six design patterns based on precision, recall, F-measure, and agreement. Results: From the 42 tools found, only ten are available for download. Altogether, the tools detect all 23 design patterns summarized by the Gang of Four's book. The comparison results suggest that some tools are more suitable for specific design patterns, e.g., the FINDER tool for Composite, Decorator and Visitor. We also observed a low agreement among tools. Conclusions: Despite the high number of tools published, design pattern detection tools are mostly ineffective and unavailable for use. Particularly, practitioners might struggle to find a tool that matches their expectations. The available tools provide inaccurate yet complementary detection results; thus, solutions for either improving or combining tools are needed. Researchers are encouraged to propose novel tools capable of filling this literature gap.},
booktitle = {Proceedings of the 29th Conference on Pattern Languages of Programs},
articleno = {17},
numpages = {16},
keywords = {design pattern, automated development tool, software design, systematic literature review, comparative study},
location = {Virtual Event},
series = {PLoP '22}
}

@article{10.1145/3561382,
author = {Yang, Deheng and Lei, Yan and Mao, Xiaoguang and Qi, Yuhua and Yi, Xin},
title = {Seeing the Whole Elephant: Systematically Understanding and Uncovering Evaluation Biases in Automated Program Repair},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3561382},
doi = {10.1145/3561382},
abstract = {Evaluation is the foundation of automated program repair (APR), as it provides empirical evidence on strengths and weaknesses of APR techniques. However, the reliability of such evaluation is often threatened by various introduced biases. Consequently, bias exploration, which uncovers biases in the APR evaluation, has become a pivotal activity and performed since the early years when pioneer APR techniques were proposed. Unfortunately, there is still no methodology to support a systematic comprehension and discovery of evaluation biases in APR, which impedes the mitigation of such biases and threatens the evaluation of APR techniques.In this work, we propose to systematically understand existing evaluation biases by rigorously conducting the first systematic literature review on existing known biases and systematically uncover new biases by building a taxonomy that categorizes evaluation biases. As a result, we identify 17 investigated biases and uncover a new bias in the usage of patch validation strategies. To validate this new bias, we devise and implement an executable framework APRConfig, based on which we evaluate three typical patch validation strategies with four representative heuristic-based and constraint-based APR techniques on three bug datasets. Overall, this article distills 13 findings for bias understanding, discovery, and validation. The systematic exploration we performed and the open source executable framework we proposed in this article provide new insights as well as an infrastructure for future exploration and mitigation of biases in APR evaluation.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {apr},
articleno = {65},
numpages = {37},
keywords = {empirical evaluation, bias study, Automated program repair}
}

@inproceedings{10.1145/3592813.3592925,
author = {Candido De Melo, Ana Carolina and Accioly, Nath\'{a}Lia and Fagundes, Roberta and Santos, Wylliams},
title = {Identifying and Measuring Technical Debt in Software Requirements: A Supporting Guide},
year = {2023},
isbn = {9798400707599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3592813.3592925},
doi = {10.1145/3592813.3592925},
abstract = {Context: Identification and measurement are the first steps in managing a Technical Debt (TD). They are essential to know the type of TD and estimate its impact on the software. Problem: However, in requirements engineering, these steps are little explored in academic research since the measurement is considered one of the most challenging phases. Solution: This work aims to develop a support guide to help software development professionals identify and measure the TD of requirements in their projects. IS Theory: This work was conceived under the aegis of the Customer Focus Theory. The requirements of TD management directly impact the quality of the product that will be delivered to the customer. Method: Initially, a systematic literature review was conducted, and a survey was applied with software development professionals allocated to different organizations. Additionally, the guide was developed and evaluated by four specialists through a focus group session. Summary of Results: Among the results, it became possible to present the existing strategies that help identify and measure the DT of requirements, in addition to tools and metrics that are used to automate the management process. Contributions and Impact in the IS area: After analyzing the results, it can be concluded that the guide is a resource that helps, especially professionals with a low level of knowledge in the area, obtain more information about TD. In addition, one of the contributions is investigating an interdisciplinary area, as TD involves social, technological, and organizational aspects.},
booktitle = {Proceedings of the XIX Brazilian Symposium on Information Systems},
pages = {356–363},
numpages = {8},
keywords = {Support Guide, Identification, Measurement., Technical Debt},
location = {Macei\'{o}, Brazil},
series = {SBSI '23}
}

@inproceedings{10.1109/ICSE48619.2023.00203,
author = {Tufano, Rosalia and Pascarella, Luca and Bavota, Gabriele},
title = {Automating Code-Related Tasks Through Transformers: The Impact of Pre-Training},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00203},
doi = {10.1109/ICSE48619.2023.00203},
abstract = {Transformers have gained popularity in the software engineering (SE) literature. These deep learning models are usually pre-trained through a self-supervised objective, meant to provide the model with basic knowledge about a language of interest (e.g., Java). A classic pre-training objective is the masked language model (MLM), in which a percentage of tokens from the input (e.g., a Java method) is masked, with the model in charge of predicting them. Once pre-trained, the model is then fine-tuned to support the specific downstream task of interest (e.g., code summarization). While there is evidence suggesting the boost in performance provided by pre-training, little is known about the impact of the specific pre-training objective(s) used. Indeed, MLM is just one of the possible pre-training objectives and recent work from the natural language processing field suggest that pre-training objectives tailored for the specific downstream task of interest may substantially boost the model's performance. For example, in the case of code summarization, a tailored pre-training objective could be the identification of an appropriate name for a given method, considering the method name to generate as an extreme summary. In this study, we focus on the impact of pre-training objectives on the performance of transformers when automating code-related tasks. We start with a systematic literature review aimed at identifying the pre-training objectives used in SE. Then, we pre-train 32 transformers using both (i) generic pre-training objectives usually adopted in SE; and (ii) pre-training objectives tailored to specific code-related tasks subject of our experimentation, namely bug-fixing, code summarization, and code completion. We also compare the pre-trained models with non pre-trained ones and show the advantage brought by pre-training in different scenarios, in which more or less fine-tuning data are available. Our results show that: (i) pre-training helps in boosting performance only if the amount of fine-tuning data available is small; (ii) the MLM objective is usually sufficient to maximize the prediction performance of the model, even when comparing it with pre-training objectives specialized for the downstream task at hand.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2425–2437},
numpages = {13},
keywords = {pre-training, code recommenders},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/3631976,
author = {Cederbladh, Johan and Cicchetti, Antonio and Suryadevara, Jagadish},
title = {Early Validation and Verification of System Behaviour in Model-Based Systems Engineering: A Systematic Literature Review},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3631976},
doi = {10.1145/3631976},
abstract = {In the Systems Engineering (SE) domain there has been a paradigm shift from document-based to model-based system development artefacts; in fact, new methodologies are emerging to meet the increasing complexity of current systems and the corresponding growing need of digital workflows. In this regard, Model-Based Systems Engineering (MBSE) is considered as a key enabler by many central players of the SE community. MBSE has reached an adequate level of maturity and there exist documented success stories in its adoption in industry. In particular, one significant benefit of utilising MBSE when compared to the traditional manual and document-centric workflows is that models are available from early phases of systems development; these enable a multitude of analyses prior any implementation effort together with other relevant capabilities, like the automation of development tasks. Nonetheless, it is noticeable there is a lack of a common understanding for how formal analyses for the verification and validation (V&amp;V) of systems behaviour, specifically in the early phases of development, could be placed in an MBSE setting. In this article, we report on the planning, execution, and results of a systematic literature review regarding the early V&amp;V of systems behaviour in the context of model-based systems engineering. The review aims to provide a structured representation of the state-of-the-art with respect to motivations, proposed solutions, and limitations. From an initial set of potentially relevant 701 peer-reviewed publications we selected 149 primary studies, which we analysed according to a rigorous data extraction, analysis, and synthesis process. Based on our results, early V&amp;V has usually the goal of checking the quality of a system design to avoid discovering flaws when parts are being concretely realised; SysML is a de facto standard for describing the system under study, while the solutions for the analyses tend to be varied; also V&amp;V analyses tend to target varied properties with a slight predominance of functional concerns, and following the variation mentioned so far the proposed solutions are largely context specific; the proposed approaches are usually presented without explicit limitations, while when limitations are discussed, readiness of the solutions, handling of analyses simplifications/assumptions, and languages/tools integration are among the most frequently mentioned issues. Based on the survey results and the standard SE practices, we discuss how the current state-of-the-art MBSE supports early V&amp;V of systems behaviour with a special focus on industrial adoption, and identify relevant challenges to be researched further.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {nov},
keywords = {System behaviour, Verification, Validation, MBSE, Systematic literature review}
}

@inproceedings{10.1145/3474624.3476008,
author = {Santos, Vinicius and Iwazaki, Anderson and Souza, \'{E}rica and Felizardo, Katia and Vijaykumar, Nandamudi},
title = {CrowdSLR: A Tool to Support the Use of Crowdsourcing in Systematic Literature Reviews},
year = {2021},
isbn = {9781450390613},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474624.3476008},
doi = {10.1145/3474624.3476008},
abstract = {Systematic Literature Reviews (SLR) have been used by Software Engineering (SE) community to produce reliable scientific evidence. An SLR process can be exhaustive and time-consuming, therefore, many approaches have been proposed to reduce time and efforts during the SLR conduction process. Although the SLR process is amenable to automation, nowadays full automation is not yet possible. An alternative to reduce time and efforts in SLR conduction is the use of crowdsourcing. However, there is no crowdsourcing tool to support a crowd-based SLR process. In this context, we present CrowdSLR, a tool to support the application of crowdsourcing in SLR during the selection of primary studies. Furthermore, we present its main features, potential users, and the architecture that was implemented to allow researchers to adopt this tool. The results of the CrowdSLR application indicate that the tool is able to provide the use crowdsourcing during the SLR selection process. The results that the proposed tool, indeed, show a significant improvement in the crowdsourcing approach in terms of time and effort to facilitate the SLR selection activity. Demo Video: https://youtu.be/UoQTC-R-Mv0},
booktitle = {Proceedings of the XXXV Brazilian Symposium on Software Engineering},
pages = {341–346},
numpages = {6},
keywords = {Systematic Literature Review, Tool, SLR, Crowdsourcing},
location = {Joinville, Brazil},
series = {SBES '21}
}

@inproceedings{10.1145/3593434.3594240,
author = {Faaiz, Syed Muhammad and Khan, Saif-Ur-Rehman and Hussain, Shahid and Wang, Wen-Li and Ibrahim, Naseem},
title = {A Study on Management Challenges and Practices in DevOps},
year = {2023},
isbn = {9798400700446},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593434.3594240},
doi = {10.1145/3593434.3594240},
abstract = {DevOps is a widely adopted practice to consistently develop and upgrade a system that is already in use. Between software development and operations, DevOps presupposes cross-functional cooperation and automation. The adoption and execution of DevOps in businesses are complicated since it necessitates adjustments to organizational, technical, and cultural factors. The implementation of DevOps in practice is thoroughly described in this systemic literature review (SLR). The study focuses on the identification of the manager's challenges in the DevOps environment and also intends to find the mitigation practices. In this article, SLR has been performed to identify the manager's challenges and the state-of-the-art mitigation strategies. This study identifies twenty challenges from the manager's perspective and the applied mitigation strategies to overcome the challenges. The findings of the current work would be beneficial in comprehending the DevOps idea, methods, and perceived impacts, particularly among managers while adopting DevOps in the organization.},
booktitle = {Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering},
pages = {430–437},
numpages = {8},
keywords = {DevOps, Taxonomy, Challenging Factors, DevOps manager, management challenges, Mitigation strategy},
location = {Oulu, Finland},
series = {EASE '23}
}

